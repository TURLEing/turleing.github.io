<!DOCTYPE html>
<html lang="zh-CN">
  <head>
  <meta charset="UTF-8">
  <meta 
    name="viewport"
    content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
  <meta 
    http-equiv="X-UA-Compatible" 
    content="ie=edge">
  <meta 
    name="theme-color" 
    content="#fff" 
    id="theme-color">
  <meta 
    name="description" 
    content="天泽龟的龟壳屋">
  <link 
    rel="icon" 
    href="https://i.loli.net/2021/07/16/yKghkEQWcY34rOU.jpg">
  <title>大模型相关论文阅读笔记</title>
  
    
      <meta 
        property="og:title" 
        content="大模型相关论文阅读笔记">
    
    
      <meta 
        property="og:url" 
        content="https://tzturtle.moe/2023/07/04/LLM-learning/index.html">
    
    
      <meta 
        property="og:img" 
        content="https://i.loli.net/2021/07/16/yKghkEQWcY34rOU.jpg">
    
    
      <meta 
        property="og:img" 
        content="&lt;p&gt;有幸参加了南大 NLP 夏令营，导师安排了一些读论文的任务，除了经典的“那篇论文”以外都没读过。这篇博客会简单记一些论文中核心的点（结合其他博客），不会去钻研细节，毕竟得一礼拜速通理论，目前仍然是完全没有实践的状态。&lt;/p&gt;">
    
    
      <meta 
        property="og:type" 
        content="article">
      <meta 
        property="og:article:published_time" 
        content="2023-07-04">
      <meta 
        property="og:article:modified_time" 
        content="2024-10-28">
      <meta 
        property="og:article:author" 
        content="天泽龟">
      
        
          <meta 
            property="og:article:tag" 
            content="NLP">
        
      
    
  
  <script>
    function loadScript(url, cb) {
      var script = document.createElement('script');
      script.src = url;
      if (cb) script.onload = cb;
      script.async = true;
      document.body.appendChild(script);
    }
    function loadCSS(href, data, attr) {
      var sheet = document.createElement('link');
      sheet.ref = 'stylesheet';
      sheet.href = href;
      sheet.dataset[data] = attr;
      document.head.appendChild(sheet);
    }
    function changeCSS(cssFile, data, attr) {
      var oldlink = document.querySelector(data);
      var newlink = document.createElement("link");
      newlink.setAttribute("rel", "stylesheet");
      newlink.setAttribute("href", cssFile);
      newlink.dataset.prism = attr;
      document.head.replaceChild(newlink, oldlink);
    }
  </script>
  
    
  
  <script>
    // control reverse button
    var reverseDarkList = {
      dark: 'light',
      light: 'dark'
    };
    var themeColor = {
      dark: '#1c1c1e',
      light: '#fff'
    }
    // get the data of css prefers-color-scheme
    var getCssMediaQuery = function() {
      return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
    };
    // reverse current darkmode setting function
    var reverseDarkModeSetting = function() {
      var setting = localStorage.getItem('user-color-scheme');
      if(reverseDarkList[setting]) {
        setting = reverseDarkList[setting];
      } else if(setting === null) {
        setting = reverseDarkList[getCssMediaQuery()];
      } else {
        return;
      }
      localStorage.setItem('user-color-scheme', setting);
      return setting;
    };
    // apply current darkmode setting
  </script>
  
    <script>
      var setDarkmode = function(mode) {
      var setting = mode || localStorage.getItem('user-color-scheme');
      if(setting === getCssMediaQuery()) {
        document.documentElement.removeAttribute('data-user-color-scheme');
        localStorage.removeItem('user-color-scheme');
        document.getElementById('theme-color').content = themeColor[setting];
        document.getElementById('theme-color').dataset.mode = setting;
      } else if(reverseDarkList[setting]) {
        document.documentElement.setAttribute('data-user-color-scheme', setting);
        document.getElementById('theme-color').content = themeColor[setting];
        document.getElementById('theme-color').dataset.mode = setting;
      } else {
        document.documentElement.removeAttribute('data-user-color-scheme');
        localStorage.removeItem('user-color-scheme');
        document.getElementById('theme-color').content = themeColor[getCssMediaQuery()];
        document.getElementById('theme-color').dataset.mode = getCssMediaQuery();
      }
    };
    setDarkmode();
    </script>
  
  
  <link rel="preload" href="//at.alicdn.com/t/font_1946621_i1kgafibvw.css" as="style" >
  <link rel="preload" href="//at.alicdn.com/t/font_1952792_89b4ac4k4up.css" as="style" >
  
  
    <link rel="preload" href="/js/lib/lightbox/baguetteBox.min.js" as="script">
    <link rel="preload" href="/js/lib/lightbox/baguetteBox.min.css" as="style" >
  
  
    <link rel="preload" href="/js/lib/lozad.min.js" as="script">
  
  
  
  
    
    <link rel="prefetch" href="//cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" as="script">
  
  
    
    <link rel="prefetch" href="//unpkg.com/valine/dist/Valine.min.js" as="script">
  
  
  
  <link rel="stylesheet" href="/css/main.css">
  
  <link rel="stylesheet" href="//at.alicdn.com/t/font_1946621_i1kgafibvw.css">
  
  <link rel="stylesheet" href="//at.alicdn.com/t/font_1952792_89b4ac4k4up.css">
  
    <link rel="stylesheet" href="/js/lib/lightbox/baguetteBox.min.css">
  
<meta name="generator" content="Hexo 5.4.0"></head>

  <body>
    <div class="wrapper">
       
      <nav class="navbar">
  <div class="navbar-logo">
    <span class="navbar-logo-main">
      
        <img 
          class="navbar-logo-img" 
          src="https://i.loli.net/2021/07/16/yKghkEQWcY34rOU.jpg" 
          alt="blog logo">
      
      <span class="navbar-logo-dsc">天泽龟的龟壳屋</span>
    </span>
  </div>
  <div class="navbar-menu">
    
      <a 
        href="/" 
        class="navbar-menu-item">
        
          首页
        
      </a>
    
      <a 
        href="/archives" 
        class="navbar-menu-item">
        
          归档
        
      </a>
    
      <a 
        href="/tags" 
        class="navbar-menu-item">
        
          标签
        
      </a>
    
      <a 
        href="/categories" 
        class="navbar-menu-item">
        
          分类
        
      </a>
    
      <a 
        href="/about" 
        class="navbar-menu-item">
        
          关于
        
      </a>
    
      <a 
        href="/links" 
        class="navbar-menu-item">
        
          友链
        
      </a>
    
      <a 
        href="/bangumis" 
        class="navbar-menu-item">
        
          番剧
        
      </a>
    
    <a 
      class="navbar-menu-item darknavbar" 
      id="dark">
      <i class="iconfont icon-weather"></i>
    </a>
    <a 
      class="navbar-menu-item searchnavbar" 
      id="search">
      <i 
        class="iconfont icon-search" 
        style="font-size: 1.2rem; font-weight: 400;">
      </i>
    </a>
  </div>
</nav> 
      
      <div 
        id="local-search" 
        style="display: none">
        <input
          class="navbar-menu-item"
          id="search-input"
          placeholder="请输入搜索内容..." />
        <div id="search-content"></div>
      </div>
      
      <div class="section-wrap">
        <div class="container">
          <div class="columns">
            <main class="main-column">
<article class="card card-content">
  <header>
    <h1 class="post-title">
      大模型相关论文阅读笔记
    </h1>
  </header>
  <div class="post-meta post-show-meta">
    <time datetime="2023-07-04T03:24:25.000Z">
      <i 
        class="iconfont icon-calendar" 
        style="margin-right: 2px;">
      </i>
      <span>2023-07-04</span>
    </time>
    
      <span class="dot"></span>
      
        <a 
          href="/categories/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/" 
          class="post-meta-link">
          科研学习
        </a>
      
    
    
      <span class="dot"></span>
      <span>2.9k 字</span>
    
  </div>
  
    <div 
      class="post-meta post-show-meta" 
      style="margin-top: -10px;">
      <div style="display: flex; align-items: center;">
        <i 
          class="iconfont icon-biaoqian" 
          style="margin-right: 2px; font-size: 1.15rem;">
        </i>
        
          
          <a 
            href="/tags/NLP/" 
            class="post-meta-link">
            NLP
          </a>
        
      </div>
    </div>
  
  </header>
  <div 
    id="section" 
    class="post-content">
    <p>有幸参加了南大 NLP 夏令营，导师安排了一些读论文的任务，除了经典的“那篇论文”以外都没读过。这篇博客会简单记一些论文中核心的点（结合其他博客），不会去钻研细节，毕竟得一礼拜速通理论，目前仍然是完全没有实践的状态。</p>
<span id="more"></span>
<h2 id="一-大语言模型"><a class="markdownIt-Anchor" href="#一-大语言模型"></a> 一。大语言模型</h2>
<p>要求详细地看一下 <code>Transformer</code> 模型，这个我之前已经写过博客了：<a target="_blank" rel="noopener" href="https://turleing.github.io/2023/05/08/Transformer-learning/">Transformer 学习笔记</a>。除此之外，还需要对两个常见的预训练模型家族 BERT、GPT 有一定了解。</p>
<h3 id="11-bert"><a class="markdownIt-Anchor" href="#11-bert"></a> 1.1 BERT</h3>
<p>BERT 是把基于特征的预训练模型 <code>ELMo</code> 可以做双向训练的优势，运用基于微调的 <code>GPT</code> 的 <code>Transformer</code> 架构上的大模型。其训练过程依然是 “预训练+微调”，即先通过完形填空 + 句子预测（NSP）的任务去训练参数，再根据下游任务进行微调。</p>
<p>BERT 的输入可以是一个句子，也可以是句子对（因为只有编码器。输入的第一个元素是起始符 <code>[CLS]</code>，不同的句子之间用 <code>[SEQ]</code> 分割。根据下游任务的需求，要么是用 <code>[CLS]</code> 所对应的输出来判断情感等分类任务，要么是根据每个词元的输出做 QA 系统、序列标注等序列生成的事情。</p>
<h3 id="12-gpt"><a class="markdownIt-Anchor" href="#12-gpt"></a> 1.2 GPT</h3>
<p>初代 GPT 利用了半监督学习的方法来应对语言理解任务，具体是混合了无监督学习的预训练和有监督学习的微调。</p>
<p>对于一系列无标签语料 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>U</mi><mo>=</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>u</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>u</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">U= u_1,u_2,...,u_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> ，使用标准的语言建模目标来最大化以下似然：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>U</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mi>i</mi></munder><mtext> </mtext><mi>P</mi><mo stretchy="false">(</mo><msub><mi>u</mi><mi>i</mi></msub><mtext> </mtext><mi mathvariant="normal">∣</mi><msub><mi>u</mi><mrow><mi>i</mi><mo>−</mo><mi>k</mi></mrow></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>u</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">;</mo><mi mathvariant="normal">Θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L(U) = \sum_i ~P(u_i ~|u_{i-k},..,u_{i-1}; \Theta )
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.327674em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0500050000000003em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mspace nobreak"> </span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace nobreak"> </span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">−</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">Θ</span><span class="mclose">)</span></span></span></span></span></p>
<p>其中，k 是语境窗口的大小，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Θ</mi></mrow><annotation encoding="application/x-tex">\Theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">Θ</span></span></span></span> 是当前模型的参数。在训练的过程中，<code>GPT1</code> 使用的是多层 Transformer decoder，可以在输入上下文 token 上应用多头自注意力操作，然后通过逐位置前馈层来产生目标 token 上的输出分布。</p>
<p>对于下游任务的微调操作，<code>GPT1</code> 借助分割词等操作处理输入序列，转化为结构化的输入，如有序句子对或文档、问题和答案的三元组。对于不同的任务，还需引入大量任务的定制化架构。</p>
<p><img src="image-20230704152834400.png" alt="image-20230704152834400" / srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%20300'%3E%3C/svg%3E" data-src="image-20230704152834400.png" class="lozad post-image"></p>
<h3 id="13-gpt3~35"><a class="markdownIt-Anchor" href="#13-gpt3~35"></a> 1.3 GPT3~3.5</h3>
<p>在 <code>GPT3</code> 的时代，作者意识到真正的大语言模型应该仅需要少量的实例说明便可迅速适应新的下游任务，而并非对于每个下游任务进行大量样本的 <code>fine-tune</code>。</p>
<p>而要想实现这一目的，论文作者通过实验发现，只需要增大参数量（<code>GPT3</code> 一共训练了 <strong>175billion</strong> 个参数），即可显著提高模型在 <code>Few-shot</code> 环境下的任务性能。</p>
<p>为此，作者给出了两种方案：</p>
<ul>
<li>
<p><code>Meta-learning</code>：元学习，即模型在训练阶段后具备一系列模式识别的能力和方法，并在预测过程中利用这些能力以快速适应下游任务;</p>
<p>部分研究尝试通过 <code>In-context learning</code> 的方法来实现上述过程，即给定任务说明以及简单的任务实例，要求模型进行预测任务。具体分为 <code>few-shot</code>, <code>one-shot</code>, <code>zero-shot</code> 等；</p>
</li>
<li>
<p><code>Large Scale Transformers</code>：<strong>大就是好！</strong> 大模型的 1750 亿参数会记住 <code>In-context Learning</code> 所学习的知识，从而极大提升模型的任务性能；</p>
</li>
</ul>
<p>虽然GPT3在文本翻译、问答系统、完型填空、新词使用和代数运算等任务表现不错，但在阅读理解和推理任务数据集上的表现仍有待提高。 <strong>但参考<a target="_blank" rel="noopener" href="https://yaofu.notion.site/GPT-3-5-360081d91ec245f29029d37b54573756">符神的博客</a>，初代 GPT-3 有着非常强的潜力。</strong> 这些潜力后来经过代码训练、指令微调和 RLHF 解锁，最终展示出极为强大的突现能力。</p>
<p><br></br></p>
<h2 id="二-高效微调"><a class="markdownIt-Anchor" href="#二-高效微调"></a> 二、高效微调</h2>
<p>对于预训练语言模型（PLM）进行微调，即 <code>fine-tuning</code> 的操作，一般指的是给定下游任务的数据集，对于模型中的所有参数进行调整。但是对于如今大语言模型（LLM）来说，进行全参数的“微调”显然是不可能的。</p>
<p>高效微调技术可以粗略分为以下三大类：增加额外参数、选取一部分参数更新、引入重参数化。以上三种微调方案所对应的即为 Adapter, Prefix-Tuning 以及 LoRa.</p>
<p><img src="v2-c2ccc287c6c555b30c4c7f3355b0c4f8_1440w.webp" alt="img" / srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%20300'%3E%3C/svg%3E" data-src="v2-c2ccc287c6c555b30c4c7f3355b0c4f8_1440w.webp" class="lozad post-image"></p>
<h3 id="21-adapter"><a class="markdownIt-Anchor" href="#21-adapter"></a> 2.1 Adapter</h3>
<p>Adapter 的想法是，在原有的 Transformer 层中间添加 Adapter 层，当进行 <code>fine-tuning</code> 时，只微调 Adapter 层的参数即可。这样训练不仅更快，还保证了大模型原来存储的知识不被遗忘。</p>
<p><code>AdapterFusion</code> 提出了 <strong>当下游存在多个任务</strong> 的时候，使用两阶段的 <code>Finetune</code>。第一阶段和<code>Adapter Finetune</code> 的思路一样，在预训练大模型基础上加上每个任务的 <code>adapter</code>进行微调，大模型参数不变。</p>
<p>在第二阶段，进一步冻结第一阶段训练的 <code>adapter</code> 层的参数，学习一个 <code>AdapterFusion</code> 模型。这个模型的思路是利用当前样本在FF层的输出和各个任务的 adapter 输出做<code>Cross-Attention</code>，实现从多个 <code>Adapter</code> 层的选择和融合。</p>
<p><img src="image-20230706004955616.png" alt="image-20230706004955616" / srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%20300'%3E%3C/svg%3E" data-src="image-20230706004955616.png" class="lozad post-image"></p>
<h3 id="22-prefix-tuning"><a class="markdownIt-Anchor" href="#22-prefix-tuning"></a> 2.2 Prefix-Tuning</h3>
<p>在 Transformer 层之前加一个 prefix block，对于每个任务仅微调其前缀块的参数，并冻结预训练模型的参数。这样对于不同的任务，只需要 finetune 不同的前缀。</p>
<p><img src="image-20230706134744885.png" alt="image-20230706134744885" / srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%20300'%3E%3C/svg%3E" data-src="image-20230706134744885.png" class="lozad post-image"></p>
<p>相比较于简单易懂的 Prompt Tuning，Prefix Tuning 采用的是添加一系列连续的 Word Embedding，并向上通过所有 Transformer 块，向右传播至后续 Token。</p>
<p>举例说，假设原来的 Input 是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">[</mo><mi>x</mi><mo separator="true">;</mo><mi>y</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[x;y]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathdefault">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">]</span></span></span></span>，那么Prefix Tuning 的 Input 即为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">[</mo><mi>P</mi><mo separator="true">,</mo><mi>x</mi><mo separator="true">;</mo><msup><mi>P</mi><mo mathvariant="normal">′</mo></msup><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[P,x;P&#x27;,y]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.001892em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">]</span></span></span></span>； 前缀的参数是通过一个矩阵 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>P</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">P_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 存储的，目标函数与 finetune 类似：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mrow><mi>ϕ</mi><mo separator="true">,</mo><mi>θ</mi></mrow></msub><mo stretchy="false">(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><msub><mi>Y</mi><mrow><mi>i</mi><mi>d</mi><mi>x</mi></mrow></msub></mrow></munder><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mrow><mi>ϕ</mi><mo separator="true">,</mo><mi>θ</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>z</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>h</mi><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\max_\theta \log p_{\phi,\theta}(y|x) = \sum_{i\in    Y_{idx}}\log p_{\phi,\theta}(z_i|h_{\lt i})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.502108em;vertical-align:-0.752108em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.752108em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">ϕ</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.450201em;vertical-align:-1.400196em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.855664em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:-0.22222em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.400196em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">ϕ</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.17737em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>在实际应用中，会加一层扩大维数的MLP，即 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>P</mi><mi>θ</mi></msub><mo>=</mo><mi>M</mi><mi>L</mi><mi>P</mi><mo stretchy="false">(</mo><msubsup><mi>P</mi><mi>θ</mi><mo mathvariant="normal">′</mo></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P_\theta = MLP(P&#x27;_{\theta})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.035em;vertical-align:-0.2831079999999999em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mord mathdefault">L</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，最后保留 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>P</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">P_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 即可。</p>
<h2 id="23-lora"><a class="markdownIt-Anchor" href="#23-lora"></a> 2.3 LoRa</h2>
<p>LoRa 感觉也不难，就是为原来的单纯的一个线性层变换，增加了一个 <code>low-rank</code> 的参数r，以及 (r, d) 和 (d, r) 的两个线性层。从而有 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>h</mi><mo>=</mo><msub><mi>W</mi><mn>0</mn></msub><mi>x</mi><mo>+</mo><mi>B</mi><mi>A</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">h=W_0x+BAx</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord mathdefault">A</span><span class="mord mathdefault">x</span></span></span></span> .</p>
<p><img src="image-20230706142739260.png" alt="image-20230706142739260" / srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%20300'%3E%3C/svg%3E" data-src="image-20230706142739260.png" class="lozad post-image"></p>
<p>微调的时候只需要对 A, B 两个线性层调参即可。</p>
<p><br></br></p>
<h2 id="三-提示词策略"><a class="markdownIt-Anchor" href="#三-提示词策略"></a> 三、提示词策略</h2>
<p>主要是 In-Context Learning 以及 Chain of Thought，这两个也挺直白的，结合 <code>ChatGPT</code> 简单提两嘴：</p>
<p><code>In-Context Learning</code>（上下文学习）的关键思想是从类比中学习。它需要一些示例来形成一个演示上下文。这些示例通常是用自然语言模板编写的。然后，ICL将查询的问题和一个上下文演示（一些相关的案例）连接在一起，形成带有提示的输入，并将其输入到语言模型中进行预测。</p>
<p>而 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2202.12837">这篇论文</a> 所指出的是，上下文的目的并非是学习输入与标注之间的关联，而是通过展示数据形式，来激活预训练模型的能力。</p>
<p>而 <code>Chain of Thought</code>的提出，展示了 “Let’s think step by step” 这个提示可以引导模型通过示例中一步一步的推理方式，去解决复杂的多步推理，在数学推理和符号推理中取得了 SOTA 的成果。</p>
<p><br></br></p>
<h2 id="四-个性化生成"><a class="markdownIt-Anchor" href="#四-个性化生成"></a> 四、个性化生成</h2>
<p>个性化文本生成旨在通过分析用户需求、喜好和行为特征，为用户提供量身定制的文本生成服务。尽管<code>ChatGPT</code> 此类基于大规模语言模型的对话系统近期为用户带来了颠覆性的体验，但其在个性化生成方面仍有所欠缺，难以满足不同用户在各种场景下的需求。</p>
<h3 id="41-个性化人机对话系统"><a class="markdownIt-Anchor" href="#41-个性化人机对话系统"></a> 4.1 个性化人机对话系统</h3>
<p>赋予对话系统以人格，这对于生成类似人类之间的对话来说十分重要。但是由于自然语言中的 <strong>“个性嵌入”</strong> 问题、以及绝大对话语料库中所存在的 <strong>“个性稀缺”</strong> 问题，实际操作起来仍有难度。</p>
<p>本文采用 <code>Encoder-Decodoer</code> 框架，在 <code>encoder</code> 中使用 <strong>属性嵌入</strong> 以捕捉和性格有很强联系的特征，在 <code>decoder</code> 中使用 <strong>注意力路由（attention routing）</strong> 以将性格嵌入到对话中。</p>
<p>目标是产生一个 <code>Response Y</code>，使得在<code>语境C</code>以及<code>个性T</code>下最优：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi><mo>=</mo><mi>arg</mi><mo>⁡</mo><mi>max</mi><mo>⁡</mo><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mi mathvariant="normal">∣</mi><mtext> </mtext><mi>C</mi><mo separator="true">,</mo><mi>T</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Y = \arg \max P(Y|~ C,T)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">max</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mord">∣</span><span class="mspace nobreak"> </span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mclose">)</span></span></span></span></span></p>
<p>其中，<code>个性T</code> 可以视为一个键值对的集合，包含性别、喜好标签等；而 <code>语境C</code> 可表示为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">(</mo><msub><mi>U</mi><mi>i</mi></msub><mo separator="true">,</mo><mtext> </mtext><msub><mi>T</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(U_i,~T_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mspace nobreak"> </span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 的集合，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>U</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">U_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 对应对话内容，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">T_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 对应对话个性。</p>
<p>模型对应的框架结构如下：</p>
<p><img src="image-20230705155758036.png" alt="image-20230705155758036" / srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%20300'%3E%3C/svg%3E" data-src="image-20230705155758036.png" class="lozad post-image"></p>
<p>其中 <code>语境C</code> 添加的属性嵌入用以标注每条对话所蕴含的个性。但是这种属性嵌入感觉没啥含金量，都是预设好的三个值（性别、居住地、爱好），感觉有点鸡肋。</p>
<p>解码器中的注意力路由可以控制目标人格 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>E</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">E_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 对于解码过程的影响，这东西本质上就是三个多头注意力层，分别处理<strong>个性、语境和之前生成的文本</strong> ，并根据个性权重<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span></span></span></span> 得到最终输出，这是通过一个动态权重预测块（分类器）计算出来的。</p>
<p>虽然说是要做个性化对话系统，但论文里给出的例子除了二者的居住地信息以外，没看出来有啥突出个性的地方。</p>
<h3 id="42-基于推荐系统的个性化"><a class="markdownIt-Anchor" href="#42-基于推荐系统的个性化"></a> 4.2 基于推荐系统的个性化</h3>
<p>第二篇 paper 在可解释推荐这个课题上，提出一种个性化 <code>Transformer</code>。</p>
<p>可解释推荐可以这样定义：给定一个用户ID和一个产品ID，生成一句话来解释为什么这个产品要推荐给这个用户。既然这种 ID 可以存储个性化信息，那就可以利用这个信息 做个性化的文本生成任务。</p>
<p>作者在输入的开头加了两个 Token，分别代表 <code>UserID</code>以及<code>ProductID</code>，这个 <strong>Token对</strong> 可以通过 MLP 转化为上下文向量；但对于 Transformer 来说，token对出现的频率远小于单词出现的频率，如果单将这个 token对 视为一个词放进 Transformer 摁 train，很大概率会被视作词表外（OOV）。</p>
<p>因此，作者设计了一个 <strong>“上下文预测”</strong> 的任务，通过产品ID对应的向量去预测生成解释文本中出现的单词，从而将ID信息与推荐文本联系起来。除此以外，还设计了 <strong>“评分预测”</strong> 以及 <strong>“解释生成”</strong> 去满足个性化推荐的需要。</p>
<p><img src="v2-39977d62957cf0f3644f937d459bd172_720w.webp" alt="img" / srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%20300'%3E%3C/svg%3E" data-src="v2-39977d62957cf0f3644f937d459bd172_720w.webp" class="lozad post-image"></p>
<p><br></br></p>
<h2 id="五-文本生成通识"><a class="markdownIt-Anchor" href="#五-文本生成通识"></a> 五、文本生成（通识</h2>
<p>（模型）编码器-解码器框架 和 仅解码器框架的区别是，输入X 和 输出y 是否共享同一组参数的网络结构。</p>
<p>（推理）基于搜索的推理 &amp; 基于采样的推理，前者追求准确度，后者追求随机性（surprise）。</p>
<p>（评估）模型生成的句子和参考句之间的相似度，基于模型的自动评价；对于故事生成，采用人类评价。</p>

  </div>
  <div>
    
      <div 
        class="post-note note-warning copyright" 
        style="margin-top: 42px">
        <p>
          <span style="font-weight: bold;">作者：</span><a 
            target="_blank" 
            rel="nofollow noopener noreferrer" 
            href="/about">
            天泽龟
          </a>
        </p>
        <p>
          <span style="font-weight: bold;">文章链接：</span><a 
            target="_blank" 
            rel="nofollow noopener noreferrer" 
            href="https://tzturtle.moe/2023/07/04/LLM-learning/">
            https://tzturtle.moe/2023/07/04/LLM-learning/
          </a>
        </p>
        <p><span style="font-weight: bold;">版权声明：</span>本博客所有文章除特别声明外，均采用<a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0 协议</a>。转载请注明出处！</p>
      </div>
    
  </div>
</article>
<div class="nav">
  
    <div class="nav-item-prev">
      <a 
        href="/2023/07/21/Personalized_Transformer/" 
        class="nav-link">
        <i class="iconfont icon-left nav-prev-icon"></i>
        <div>
          <div class="nav-label">上一篇</div>
          
            <div class="nav-title">记人生第一次论文复现以及微小的改进 </div>
          
        </div>
      </a>
    </div>
  
  
    <div class="nav-item-next">
      <a 
        href="/2023/05/08/Transformer-learning/" 
        class="nav-link">
        <div>
          <div class="nav-label">下一篇</div>
          
            <div class="nav-title">Transformer 学习笔记 </div>
          
        </div>
        <i class="iconfont icon-right nav-next-icon"></i>
      </a>
    </div>
  
</div>

  <div 
    class="card card-content comment-card" 
    style="margin-top: 16px;">
    <div class="comment-card-title">评论</div>
    
  <div id="vcomments"></div>
  
  <script>
    loadScript("//unpkg.com/valine/dist/Valine.min.js");
    var oldLoadVa = window.onload;
    window.onload = function () {
      oldLoadVa && oldLoadVa();
      new Valine({
        el: '#vcomments',
        appId: '4CiiPBXpbjDnPvIIwfuEPEY6-gzGzoHsz',
        appKey: '3AQY35K3Laq9fLvTG2uOHDUT',
        placeholder: '留下你的评论...',
        path: window.location.pathname,
        avatar: 'identicon',
        meta: ["nick","mail","link"],
        pageSize: '10',
        lang: '',
        visitor: 'false',
        highlight: true,
        recordIP: false,
        
        
        
        enableQQ: 'true',
        requiredFields: [],
      });
    };
  </script>

  </div>

<div 
  class="card card-content toc-card" 
  id="mobiletoc">
  <div class="toc-header">
  <i 
    class="iconfont icon-menu" 
    style="padding-right: 2px;">
  </i>目录
</div>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="toc-text"> 一。大语言模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-bert"><span class="toc-text"> 1.1 BERT</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-gpt"><span class="toc-text"> 1.2 GPT</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-gpt3~35"><span class="toc-text"> 1.3 GPT3~3.5</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C-%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83"><span class="toc-text"> 二、高效微调</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#21-adapter"><span class="toc-text"> 2.1 Adapter</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-prefix-tuning"><span class="toc-text"> 2.2 Prefix-Tuning</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#23-lora"><span class="toc-text"> 2.3 LoRa</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89-%E6%8F%90%E7%A4%BA%E8%AF%8D%E7%AD%96%E7%95%A5"><span class="toc-text"> 三、提示词策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B-%E4%B8%AA%E6%80%A7%E5%8C%96%E7%94%9F%E6%88%90"><span class="toc-text"> 四、个性化生成</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#41-%E4%B8%AA%E6%80%A7%E5%8C%96%E4%BA%BA%E6%9C%BA%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F"><span class="toc-text"> 4.1 个性化人机对话系统</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#42-%E5%9F%BA%E4%BA%8E%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%B8%AA%E6%80%A7%E5%8C%96"><span class="toc-text"> 4.2 基于推荐系统的个性化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94-%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E9%80%9A%E8%AF%86"><span class="toc-text"> 五、文本生成（通识</span></a></li></ol>
</div></main>
            <aside class="left-column">
              
              <div class="card card-author">
                
  <img 
    src="https://i.loli.net/2021/07/16/yKghkEQWcY34rOU.jpg" 
    class="author-img" 
    alt="author avatar">

<p class="author-name">天泽龟</p>
<p class="author-description">天泽龟的龟是龟裂的龟哦。</p>
<div class="author-message">
  <a 
    class="author-posts-count" 
    href="/archives">
    <span>59</span>
    <span>文章</span>
  </a>
  <a 
    class="author-categories-count" 
    href="/categories">
    <span>5</span>
    <span>分类</span>
  </a>
  <a 
    class="author-tags-count" 
    href="/tags">
    <span>14</span>
    <span>标签</span>
  </a>
</div>

  <div class="author-card-society">
    
      <div class="author-card-society-icon">
        <a target="_blank" rel="noopener" href="https://space.bilibili.com/12645985">
          <i class="iconfont icon-bilibili society-icon"></i>
        </a>
      </div>
    
      <div class="author-card-society-icon">
        <a target="_blank" rel="noopener" href="https://github.com/TURLEing">
          <i class="iconfont icon-github society-icon"></i>
        </a>
      </div>
    
      <div class="author-card-society-icon">
        <a target="_blank" rel="noopener" href="https://turleing.github.io/about/">
          <i class="iconfont icon-mail society-icon"></i>
        </a>
      </div>
    
  </div>

              </div>
               <div class="sticky-tablet">
  
  
    <article class="display-when-two-columns spacer">
      <div class="card card-content toc-card">
        <div class="toc-header">
  <i 
    class="iconfont icon-menu" 
    style="padding-right: 2px;">
  </i>目录
</div>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="toc-text"> 一。大语言模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-bert"><span class="toc-text"> 1.1 BERT</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-gpt"><span class="toc-text"> 1.2 GPT</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-gpt3~35"><span class="toc-text"> 1.3 GPT3~3.5</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C-%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83"><span class="toc-text"> 二、高效微调</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#21-adapter"><span class="toc-text"> 2.1 Adapter</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-prefix-tuning"><span class="toc-text"> 2.2 Prefix-Tuning</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#23-lora"><span class="toc-text"> 2.3 LoRa</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89-%E6%8F%90%E7%A4%BA%E8%AF%8D%E7%AD%96%E7%95%A5"><span class="toc-text"> 三、提示词策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B-%E4%B8%AA%E6%80%A7%E5%8C%96%E7%94%9F%E6%88%90"><span class="toc-text"> 四、个性化生成</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#41-%E4%B8%AA%E6%80%A7%E5%8C%96%E4%BA%BA%E6%9C%BA%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F"><span class="toc-text"> 4.1 个性化人机对话系统</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#42-%E5%9F%BA%E4%BA%8E%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%B8%AA%E6%80%A7%E5%8C%96"><span class="toc-text"> 4.2 基于推荐系统的个性化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94-%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E9%80%9A%E8%AF%86"><span class="toc-text"> 五、文本生成（通识</span></a></li></ol>
      </div>
    </article>
  
  
  <article class="card card-content categories-widget">
    <div class="categories-card">
  <div class="categories-header">
    <i 
      class="iconfont icon-fenlei" 
      style="padding-right: 2px;">
    </i>分类
  </div>
  <div class="categories-list">
    
      <a href="/categories/%E7%94%9F%E6%B4%BB%E5%88%86%E4%BA%AB/">
        <div class="categories-list-item">
          生活分享
          <span class="categories-list-item-badge">10</span>
        </div>
      </a>
    
      <a href="/categories/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B/">
        <div class="categories-list-item">
          算法竞赛
          <span class="categories-list-item-badge">12</span>
        </div>
      </a>
    
      <a href="/categories/%E4%B8%93%E4%B8%9A%E5%AD%A6%E4%B9%A0/">
        <div class="categories-list-item">
          专业学习
          <span class="categories-list-item-badge">26</span>
        </div>
      </a>
    
      <a href="/categories/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/">
        <div class="categories-list-item">
          科研学习
          <span class="categories-list-item-badge">7</span>
        </div>
      </a>
    
      <a href="/categories/%E7%A4%BE%E5%9B%A2%E6%8E%A8%E9%80%81/">
        <div class="categories-list-item">
          社团推送
          <span class="categories-list-item-badge">2</span>
        </div>
      </a>
    
  </div>
</div>
  </article>
  
  <article class="card card-content tags-widget">
    <div class="tags-card">
  <div class="tags-header">
    <i 
      class="iconfont icon-biaoqian" 
      style="padding-right: 2px;">
    </i>热门标签
  </div>
  <div class="tags-list">
    
      <a 
        href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/" 
        title="计算机组成原理">
        <div class="tags-list-item">计算机组成原理</div>
      </a>
    
      <a 
        href="/tags/%E9%9A%8F%E7%AC%94/" 
        title="随笔">
        <div class="tags-list-item">随笔</div>
      </a>
    
      <a 
        href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" 
        title="强化学习">
        <div class="tags-list-item">强化学习</div>
      </a>
    
      <a 
        href="/tags/NLP/" 
        title="NLP">
        <div class="tags-list-item">NLP</div>
      </a>
    
      <a 
        href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" 
        title="操作系统">
        <div class="tags-list-item">操作系统</div>
      </a>
    
      <a 
        href="/tags/%E6%97%A5%E9%BA%BB/" 
        title="日麻">
        <div class="tags-list-item">日麻</div>
      </a>
    
      <a 
        href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/" 
        title="字符串">
        <div class="tags-list-item">字符串</div>
      </a>
    
      <a 
        href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/" 
        title="大模型">
        <div class="tags-list-item">大模型</div>
      </a>
    
      <a 
        href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" 
        title="分布式">
        <div class="tags-list-item">分布式</div>
      </a>
    
      <a 
        href="/tags/%E5%A4%9A%E9%A1%B9%E5%BC%8F/" 
        title="多项式">
        <div class="tags-list-item">多项式</div>
      </a>
    
      <a 
        href="/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" 
        title="推荐系统">
        <div class="tags-list-item">推荐系统</div>
      </a>
    
      <a 
        href="/tags/%E5%BC%BA%E8%BF%9E%E9%80%9A%E5%88%86%E9%87%8F/" 
        title="强连通分量">
        <div class="tags-list-item">强连通分量</div>
      </a>
    
      <a 
        href="/tags/%E7%BA%BF%E6%80%A7%E5%9F%BA/" 
        title="线性基">
        <div class="tags-list-item">线性基</div>
      </a>
    
      <a 
        href="/tags/%E5%8D%9A%E5%BC%88%E8%AE%BA/" 
        title="博弈论">
        <div class="tags-list-item">博弈论</div>
      </a>
    
  </div>
</div>
  </article>
  
  
</div>
            </aside>
            <aside class="right-column">
              <div class="sticky-widescreen">
  
  
    <article class="card card-content toc-card">
      <div class="toc-header">
  <i 
    class="iconfont icon-menu" 
    style="padding-right: 2px;">
  </i>目录
</div>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="toc-text"> 一。大语言模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-bert"><span class="toc-text"> 1.1 BERT</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-gpt"><span class="toc-text"> 1.2 GPT</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-gpt3~35"><span class="toc-text"> 1.3 GPT3~3.5</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C-%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83"><span class="toc-text"> 二、高效微调</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#21-adapter"><span class="toc-text"> 2.1 Adapter</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-prefix-tuning"><span class="toc-text"> 2.2 Prefix-Tuning</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#23-lora"><span class="toc-text"> 2.3 LoRa</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89-%E6%8F%90%E7%A4%BA%E8%AF%8D%E7%AD%96%E7%95%A5"><span class="toc-text"> 三、提示词策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B-%E4%B8%AA%E6%80%A7%E5%8C%96%E7%94%9F%E6%88%90"><span class="toc-text"> 四、个性化生成</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#41-%E4%B8%AA%E6%80%A7%E5%8C%96%E4%BA%BA%E6%9C%BA%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F"><span class="toc-text"> 4.1 个性化人机对话系统</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#42-%E5%9F%BA%E4%BA%8E%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%B8%AA%E6%80%A7%E5%8C%96"><span class="toc-text"> 4.2 基于推荐系统的个性化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94-%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E9%80%9A%E8%AF%86"><span class="toc-text"> 五、文本生成（通识</span></a></li></ol>
    </article>
  
  
  <article class="card card-content">
    <div class="recent-posts-card">
  <div class="recent-posts-header">
    <i 
      class="iconfont icon-wenzhang_huaban" 
      style="padding-right: 2px;">
    </i>最近文章
  </div>
  <div class="recent-posts-list">
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2025-07-21</div>
        <a href="/2025/07/21/Rl-reproduce/"><div class="recent-posts-item-content">RL 实验复现随笔</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2025-07-16</div>
        <a href="/2025/07/16/daily-story-pyenv-conda/"><div class="recent-posts-item-content">【实验室小品一则】什么是pyenv，什么是miniconda</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2025-06-06</div>
        <a href="/2025/06/06/memory-for-404/"><div class="recent-posts-item-content">缅怀我第一位逝去的朋友</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2025-03-08</div>
        <a href="/2025/03/08/rl-mario/"><div class="recent-posts-item-content">强化学习实战：用PPO算法通关超级马里奥兄弟</div></a>
      </div>
    
  </div>
</div>
  </article>
  
  
</div>
            </aside>
          </div>
        </div>
      </div>
    </div>
     
    <footer class="footer">
  <div class="footer-container">
    <div>
      <div class="footer-dsc">
        <span>
          Copyright ©
          
            2020 -
          
          2025
        </span>
        &nbsp;
        <a 
          href="/" 
          class="footer-link">
          天泽龟的龟壳屋
        </a>
      </div>
    </div>

    
      <div class="footer-dsc">
        
          Powered by
          <a 
            href="https://hexo.io/" 
            class="footer-link" 
            target="_blank" 
            rel="nofollow noopener noreferrer">
            &nbsp;Hexo
          </a>
        
        
          <span>&nbsp;|&nbsp;</span>
        
        
          Theme -
          <a 
            href="https://github.com/theme-kaze" 
            class="footer-link" 
            target="_blank"
            rel="nofollow noopener noreferrer">
            &nbsp;Kaze
          </a>
        
      </div>
    
    
    
    
      <div class="footer-dsc">
        
          本站总访问量<span id="busuanzi_value_site_pv"></span>次
        
        
          <span>&nbsp;|&nbsp;</span>
        
        
          本站总访客数<span id="busuanzi_value_site_uv"></span>次
        
      </div>
      
    
</footer> 
    
  <a 
    role="button" 
    id="scrollbutton" 
    class="basebutton" 
    aria-label="回到顶部">
    <i class="iconfont icon-arrowleft button-icon"></i>
  </a>

<a 
  role="button" 
  id="menubutton" 
  class="basebutton">
  <i class="iconfont icon-menu button-icon"></i>
</a>
<a 
  role="button" 
  id="popbutton" 
  class="basebutton" 
  aria-label="控制中心">
  <i class="iconfont icon-expand button-icon"></i>
</a>
<a 
  role="button" 
  id="darkbutton" 
  class="basebutton darkwidget" 
  aria-label="夜色模式">
  <i class="iconfont icon-weather button-icon"></i>
</a>
<a 
  role="button" 
  id="searchbutton" 
  class="basebutton searchwidget" 
  aria-label="搜索">
  <i class="iconfont icon-search button-icon"></i>
</a> 
     
     
      

  
  
    
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css">

  
 
     
     
      <script>
  var addImgLayout = function () {
    var img = document.querySelectorAll('.post-content img')
    var i
    for (i = 0; i < img.length; i++) {
      var wrapper = document.createElement('a')
      wrapper.setAttribute('href', img[i].getAttribute('data-src'))
      wrapper.setAttribute('aria-label', 'illustration')
      wrapper.style.cssText =
        'width: 100%; display: flex; justify-content: center;'
      if (img[i].alt) wrapper.dataset.caption = img[i].alt
      wrapper.dataset.nolink = true
      img[i].before(wrapper)
      wrapper.append(img[i])
      var divWrap = document.createElement('div')
      divWrap.classList.add('gallery')
      wrapper.before(divWrap)
      divWrap.append(wrapper)
    }
    baguetteBox.run('.gallery')
  }
</script>
<script>
  loadScript(
    "/js/lib/lightbox/baguetteBox.min.js",
    addImgLayout
  )
</script>
 
     
     
    <script src="/js/main.js"></script> 
    
      <script> 
        loadScript('/js/lib/busuanzi.min.js') 
      </script>
     
    
      <script>
        var addLazyload = function () {
          var observer = lozad('.lozad', {
            load: function (el) {
              el.srcset = el.getAttribute('data-src')
            },
            loaded: function (el) {
              el.classList.add('loaded')
            },
          })
          observer.observe()
        }
      </script>
      <script>
        loadScript('/js/lib/lozad.min.js', addLazyload)
      </script>
     
    
    
  </body>
</html>
