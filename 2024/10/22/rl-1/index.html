<!DOCTYPE html>
<html lang="zh-CN">
  <head>
  <meta charset="UTF-8">
  <meta 
    name="viewport"
    content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
  <meta 
    http-equiv="X-UA-Compatible" 
    content="ie=edge">
  <meta 
    name="theme-color" 
    content="#fff" 
    id="theme-color">
  <meta 
    name="description" 
    content="天泽龟的龟壳屋">
  <link 
    rel="icon" 
    href="https://i.loli.net/2021/07/16/yKghkEQWcY34rOU.jpg">
  <title>《动手学强化学习》学习笔记【一】</title>
  
    
      <meta 
        property="og:title" 
        content="《动手学强化学习》学习笔记【一】">
    
    
      <meta 
        property="og:url" 
        content="https://tzturtle.moe/2024/10/22/rl-1/index.html">
    
    
      <meta 
        property="og:img" 
        content="https://i.loli.net/2021/07/16/yKghkEQWcY34rOU.jpg">
    
    
    
      <meta 
        property="og:type" 
        content="article">
      <meta 
        property="og:article:published_time" 
        content="2024-10-22">
      <meta 
        property="og:article:modified_time" 
        content="2024-11-09">
      <meta 
        property="og:article:author" 
        content="天泽龟">
      
        
          <meta 
            property="og:article:tag" 
            content="强化学习">
        
      
    
  
  <script>
    function loadScript(url, cb) {
      var script = document.createElement('script');
      script.src = url;
      if (cb) script.onload = cb;
      script.async = true;
      document.body.appendChild(script);
    }
    function loadCSS(href, data, attr) {
      var sheet = document.createElement('link');
      sheet.ref = 'stylesheet';
      sheet.href = href;
      sheet.dataset[data] = attr;
      document.head.appendChild(sheet);
    }
    function changeCSS(cssFile, data, attr) {
      var oldlink = document.querySelector(data);
      var newlink = document.createElement("link");
      newlink.setAttribute("rel", "stylesheet");
      newlink.setAttribute("href", cssFile);
      newlink.dataset.prism = attr;
      document.head.replaceChild(newlink, oldlink);
    }
  </script>
  
    
  
  <script>
    // control reverse button
    var reverseDarkList = {
      dark: 'light',
      light: 'dark'
    };
    var themeColor = {
      dark: '#1c1c1e',
      light: '#fff'
    }
    // get the data of css prefers-color-scheme
    var getCssMediaQuery = function() {
      return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
    };
    // reverse current darkmode setting function
    var reverseDarkModeSetting = function() {
      var setting = localStorage.getItem('user-color-scheme');
      if(reverseDarkList[setting]) {
        setting = reverseDarkList[setting];
      } else if(setting === null) {
        setting = reverseDarkList[getCssMediaQuery()];
      } else {
        return;
      }
      localStorage.setItem('user-color-scheme', setting);
      return setting;
    };
    // apply current darkmode setting
  </script>
  
    <script>
      var setDarkmode = function(mode) {
      var setting = mode || localStorage.getItem('user-color-scheme');
      if(setting === getCssMediaQuery()) {
        document.documentElement.removeAttribute('data-user-color-scheme');
        localStorage.removeItem('user-color-scheme');
        document.getElementById('theme-color').content = themeColor[setting];
        document.getElementById('theme-color').dataset.mode = setting;
      } else if(reverseDarkList[setting]) {
        document.documentElement.setAttribute('data-user-color-scheme', setting);
        document.getElementById('theme-color').content = themeColor[setting];
        document.getElementById('theme-color').dataset.mode = setting;
      } else {
        document.documentElement.removeAttribute('data-user-color-scheme');
        localStorage.removeItem('user-color-scheme');
        document.getElementById('theme-color').content = themeColor[getCssMediaQuery()];
        document.getElementById('theme-color').dataset.mode = getCssMediaQuery();
      }
    };
    setDarkmode();
    </script>
  
  
  <link rel="preload" href="//at.alicdn.com/t/font_1946621_i1kgafibvw.css" as="style" >
  <link rel="preload" href="//at.alicdn.com/t/font_1952792_89b4ac4k4up.css" as="style" >
  
  
    <link rel="preload" href="/js/lib/lightbox/baguetteBox.min.js" as="script">
    <link rel="preload" href="/js/lib/lightbox/baguetteBox.min.css" as="style" >
  
  
    <link rel="preload" href="/js/lib/lozad.min.js" as="script">
  
  
  
  
    
    <link rel="prefetch" href="//cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" as="script">
  
  
    
    <link rel="prefetch" href="//unpkg.com/valine/dist/Valine.min.js" as="script">
  
  
  
  <link rel="stylesheet" href="/css/main.css">
  
  <link rel="stylesheet" href="//at.alicdn.com/t/font_1946621_i1kgafibvw.css">
  
  <link rel="stylesheet" href="//at.alicdn.com/t/font_1952792_89b4ac4k4up.css">
  
    <link rel="stylesheet" href="/js/lib/lightbox/baguetteBox.min.css">
  
<meta name="generator" content="Hexo 5.4.0"></head>

  <body>
    <div class="wrapper">
       
      <nav class="navbar">
  <div class="navbar-logo">
    <span class="navbar-logo-main">
      
        <img 
          class="navbar-logo-img" 
          src="https://i.loli.net/2021/07/16/yKghkEQWcY34rOU.jpg" 
          alt="blog logo">
      
      <span class="navbar-logo-dsc">天泽龟的龟壳屋</span>
    </span>
  </div>
  <div class="navbar-menu">
    
      <a 
        href="/" 
        class="navbar-menu-item">
        
          首页
        
      </a>
    
      <a 
        href="/archives" 
        class="navbar-menu-item">
        
          归档
        
      </a>
    
      <a 
        href="/tags" 
        class="navbar-menu-item">
        
          标签
        
      </a>
    
      <a 
        href="/categories" 
        class="navbar-menu-item">
        
          分类
        
      </a>
    
      <a 
        href="/about" 
        class="navbar-menu-item">
        
          关于
        
      </a>
    
      <a 
        href="/links" 
        class="navbar-menu-item">
        
          友链
        
      </a>
    
      <a 
        href="/bangumis" 
        class="navbar-menu-item">
        
          番剧
        
      </a>
    
    <a 
      class="navbar-menu-item darknavbar" 
      id="dark">
      <i class="iconfont icon-weather"></i>
    </a>
    <a 
      class="navbar-menu-item searchnavbar" 
      id="search">
      <i 
        class="iconfont icon-search" 
        style="font-size: 1.2rem; font-weight: 400;">
      </i>
    </a>
  </div>
</nav> 
      
      <div 
        id="local-search" 
        style="display: none">
        <input
          class="navbar-menu-item"
          id="search-input"
          placeholder="请输入搜索内容..." />
        <div id="search-content"></div>
      </div>
      
      <div class="section-wrap">
        <div class="container">
          <div class="columns">
            <main class="main-column">
<article class="card card-content">
  <header>
    <h1 class="post-title">
      《动手学强化学习》学习笔记【一】
    </h1>
  </header>
  <div class="post-meta post-show-meta">
    <time datetime="2024-10-22T01:37:51.000Z">
      <i 
        class="iconfont icon-calendar" 
        style="margin-right: 2px;">
      </i>
      <span>2024-10-22</span>
    </time>
    
      <span class="dot"></span>
      
        <a 
          href="/categories/%E4%B8%93%E4%B8%9A%E5%AD%A6%E4%B9%A0/" 
          class="post-meta-link">
          专业学习
        </a>
      
    
    
      <span class="dot"></span>
      <span>2.6k 字</span>
    
  </div>
  
    <div 
      class="post-meta post-show-meta" 
      style="margin-top: -10px;">
      <div style="display: flex; align-items: center;">
        <i 
          class="iconfont icon-biaoqian" 
          style="margin-right: 2px; font-size: 1.15rem;">
        </i>
        
          
          <a 
            href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" 
            class="post-meta-link">
            强化学习
          </a>
        
      </div>
    </div>
  
  </header>
  <div 
    id="section" 
    class="post-content">
    <span id="more"></span>
<h2 id="第一节-初探强化学习"><a class="markdownIt-Anchor" href="#第一节-初探强化学习"></a> 第一节 初探强化学习</h2>
<p><img src="https://hrl.boyuai.com/static/11.da5ee18f.png" alt="11.da5ee18f.png (782×711)" / srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%20300'%3E%3C/svg%3E" data-src="https://hrl.boyuai.com/static/11.da5ee18f.png" class="lozad post-image"></p>
<h3 id="1-概念"><a class="markdownIt-Anchor" href="#1-概念"></a> 1. 概念</h3>
<p><strong>广泛地讲，强化学习是机器通过与环境交互来实现目标的一种计算方法。</strong> 机器和环境的一轮交互是指，机器在环境的一个状态下做一个<strong>动作</strong>决策，把这个动作作用到<strong>环境</strong>当中，这个环境发生相应的改变并且将相应的<strong>奖励</strong>反馈和下一轮状态传回机器。这种交互是迭代进行的，<strong>机器的目标是最大化在多轮交互过程中获得的累积奖励的期望。</strong></p>
<p>强化学习用<strong>智能体（agent）<strong>这个概念来表示做决策的机器。相比于有监督学习中的“模型”，强化学习中的“智能体”强调机器</strong>不但可以感知周围的环境信息，还可以通过做决策来直接改变这个环境</strong>，而不只是给出一些预测信号。</p>
<p>这里，智能体有3种关键要素，即<strong>感知、决策和奖励</strong>。</p>
<ul>
<li>感知。智能体在某种程度上感知环境的状态，从而知道自己所处的现状。例如，下围棋的智能体感知当前的棋盘情况；无人车感知周围道路的车辆、行人和红绿灯等情况。</li>
<li>智能体根据当前的状态，计算出达到目标需要采取的动作的过程叫作决策。例如，针对当前的棋盘决定下一颗落子的位置；针对当前的路况，无人车计算出方向盘的角度和刹车、油门的力度。</li>
<li>奖励。环境根据状态和智能体采取的动作，产生一个标量信号作为奖励反馈。这个标量信号衡量智能体这一轮动作的好坏。例如，围棋博弈是否胜利；无人车是否安全、平稳且快速地行驶。【最大化累积奖励期望】是智能体提升策略的目标，也是衡量智能体策略好坏的关键指标。</li>
</ul>
<p>【面向决策任务的强化学习】和【面向预测任务的监督学习】在形式上是有不少区别的：</p>
<ul>
<li>首先，决策任务往往涉及多轮交互，即序贯决策；而预测任务总是单轮的独立任务。<strong>如果决策也是单轮的，那么它可以转化为“判别最优动作”的预测任务。</strong></li>
<li>其次，因为决策任务是多轮的，智能体就需要在每轮做决策时考虑未来环境相应的改变，所以当前轮带来最大奖励反馈的动作，<strong>在长期来看并不一定是最优的</strong>。</li>
</ul>
<h3 id="2-环境"><a class="markdownIt-Anchor" href="#2-环境"></a> 2. 环境</h3>
<p>生活中几乎所有的环境（或者说，系统）都在进行演变，例如一座城市的交通、一片湖中的生态、一场足球比赛、一个星系等，这在数学和物理中往往用随机过程来刻画。对于一个随机过程，其最关键的要素就是<strong>状态</strong>以及状态转移的<strong>条件概率分布</strong>。如果在环境这样一个自身演变的随机过程中加入一个外来的干扰因素，即智能体的动作，那么环境的下一刻状态的概率分布将由当前状态和智能体的动作来共同决定，用最简单的数学公式表示则是：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">下</mi><mi mathvariant="normal">一</mi><mi mathvariant="normal">状</mi><mi mathvariant="normal">态</mi><mo>∼</mo><mi>P</mi><mo stretchy="false">(</mo><mo>⋅</mo><mo>∣</mo><mi mathvariant="normal">当</mi><mi mathvariant="normal">前</mi><mi mathvariant="normal">状</mi><mi mathvariant="normal">态</mi><mi mathvariant="normal">，</mi><mi mathvariant="normal">智</mi><mi mathvariant="normal">能</mi><mi mathvariant="normal">体</mi><mi mathvariant="normal">的</mi><mi mathvariant="normal">动</mi><mi mathvariant="normal">作</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">下一状态 \sim P(⋅ ∣ 当前状态，智能体的动作)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord cjk_fallback">下</span><span class="mord cjk_fallback">一</span><span class="mord cjk_fallback">状</span><span class="mord cjk_fallback">态</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord">⋅</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord cjk_fallback">当</span><span class="mord cjk_fallback">前</span><span class="mord cjk_fallback">状</span><span class="mord cjk_fallback">态</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">智</span><span class="mord cjk_fallback">能</span><span class="mord cjk_fallback">体</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">动</span><span class="mord cjk_fallback">作</span><span class="mclose">)</span></span></span></span></span></p>
<p>根据上式可知，智能体决策的动作作用到环境中，使得环境发生相应的状态改变，而智能体接下来则需要在新的状态下进一步给出决策。每一轮状态转移都伴随着两方面的随机性：一是智能体决策的动作的随机性，二是环境基于当前状态和智能体动作来采样下一刻状态的随机性。</p>
<h3 id="3-目标"><a class="markdownIt-Anchor" href="#3-目标"></a> 3. 目标</h3>
<p>智能体和环境每次进行交互时，环境会产生相应的奖励信号，其往往由实数标量来表示。整个交互过程的每一轮获得的奖励信号可以进行累加，<strong>形成智能体的整体回报（return）</strong>。根据环境的动态性我们可以知道，即使环境和智能体策略不变，智能体和环境交互产生的结果也很可能是不同的，对应获得的回报也会不同。因此，在强化学习中，<strong>我们关注回报的期望，并将其定义为价值（value）</strong>，这就是强化学习中智能体学习的优化目标。</p>
<p>价值的计算有些复杂，因为需要对交互过程中每一轮智能体采取动作的概率分布和环境相应的状态转移的概率分布做积分运算。强化学习和有监督学习的学习目标其实是一致的，<strong>即在某个数据分布下优化一个分数值的期望</strong>。</p>
<p>对于一般的监督学习任务，我们的目标是找到一个最优的模型函数，使其在训练数据集上最小化一个给定的损失函数。在训练数据独立同分布的假设下，这个优化目标表示最小化模型在整个数据分布上的泛化误差（generalization error）</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">最</mi><mi mathvariant="normal">优</mi><mi mathvariant="normal">模</mi><mi mathvariant="normal">型</mi><mo>=</mo><mi>arg</mi><mo>⁡</mo><munder><mo><mi>min</mi><mo>⁡</mo></mo><mrow><mi mathvariant="normal">模</mi><mi mathvariant="normal">型</mi></mrow></munder><msub><mi>E</mi><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">特</mi><mi mathvariant="normal">征</mi><mi mathvariant="normal">，</mi><mi mathvariant="normal">标</mi><mi mathvariant="normal">签</mi><mo stretchy="false">)</mo><mo>∼</mo><mi mathvariant="normal">数</mi><mi mathvariant="normal">据</mi><mi mathvariant="normal">分</mi><mi mathvariant="normal">布</mi></mrow></msub><mo stretchy="false">[</mo><mi mathvariant="normal">损</mi><mi mathvariant="normal">失</mi><mi mathvariant="normal">函</mi><mi mathvariant="normal">数</mi><mo stretchy="false">(</mo><mi mathvariant="normal">标</mi><mi mathvariant="normal">签</mi><mi mathvariant="normal">，</mi><mi mathvariant="normal">模</mi><mi mathvariant="normal">型</mi><mo stretchy="false">(</mo><mi mathvariant="normal">特</mi><mi mathvariant="normal">征</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">最优模型 = \arg\min_{模型} E_{(特征，标签)\sim数据分布} [损失函数(标签，模型(特征))]
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord cjk_fallback">最</span><span class="mord cjk_fallback">优</span><span class="mord cjk_fallback">模</span><span class="mord cjk_fallback">型</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.45em;vertical-align:-0.7em;"></span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.66786em;"><span style="top:-2.1em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord cjk_fallback mtight">模</span><span class="mord cjk_fallback mtight">型</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord cjk_fallback mtight">特</span><span class="mord cjk_fallback mtight">征</span><span class="mord cjk_fallback mtight">，</span><span class="mord cjk_fallback mtight">标</span><span class="mord cjk_fallback mtight">签</span><span class="mclose mtight">)</span><span class="mrel mtight">∼</span><span class="mord cjk_fallback mtight">数</span><span class="mord cjk_fallback mtight">据</span><span class="mord cjk_fallback mtight">分</span><span class="mord cjk_fallback mtight">布</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord cjk_fallback">损</span><span class="mord cjk_fallback">失</span><span class="mord cjk_fallback">函</span><span class="mord cjk_fallback">数</span><span class="mopen">(</span><span class="mord cjk_fallback">标</span><span class="mord cjk_fallback">签</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">模</span><span class="mord cjk_fallback">型</span><span class="mopen">(</span><span class="mord cjk_fallback">特</span><span class="mord cjk_fallback">征</span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></span></p>
<p>奖励函数是对于未来累积奖励的预测，评估给定策略下状态的好坏。相比之下，强化学习任务的最终优化目标是最大化智能体策略在和动态环境交互过程中的价值，而策略的价值可以等价转换成奖励函数在策略的占用度量上的期望，即：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">最</mi><mi mathvariant="normal">优</mi><mi mathvariant="normal">策</mi><mi mathvariant="normal">略</mi><mo>=</mo><mi>arg</mi><mo>⁡</mo><munder><mo><mi>max</mi><mo>⁡</mo></mo><mrow><mi mathvariant="normal">策</mi><mi mathvariant="normal">略</mi></mrow></munder><msub><mi>E</mi><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">状</mi><mi mathvariant="normal">态</mi><mo separator="true">,</mo><mi mathvariant="normal">动</mi><mi mathvariant="normal">作</mi><mo stretchy="false">)</mo><mo>∼</mo><mi mathvariant="normal">策</mi><mi mathvariant="normal">略</mi><mi mathvariant="normal">的</mi><mi mathvariant="normal">占</mi><mi mathvariant="normal">用</mi><mi mathvariant="normal">度</mi><mi mathvariant="normal">量</mi></mrow></msub><mo stretchy="false">[</mo><mi mathvariant="normal">奖</mi><mi mathvariant="normal">励</mi><mi mathvariant="normal">函</mi><mi mathvariant="normal">数</mi><mo stretchy="false">(</mo><mi mathvariant="normal">状</mi><mi mathvariant="normal">态</mi><mo separator="true">,</mo><mi mathvariant="normal">动</mi><mi mathvariant="normal">作</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">最优策略=\arg\max_{策略}E_{(状态,动作)\sim策略的占用度量}[奖励函数(状态,动作)]
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord cjk_fallback">最</span><span class="mord cjk_fallback">优</span><span class="mord cjk_fallback">策</span><span class="mord cjk_fallback">略</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.45em;vertical-align:-0.7em;"></span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43056em;"><span style="top:-2.1em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord cjk_fallback mtight">策</span><span class="mord cjk_fallback mtight">略</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord cjk_fallback mtight">状</span><span class="mord cjk_fallback mtight">态</span><span class="mpunct mtight">,</span><span class="mord cjk_fallback mtight">动</span><span class="mord cjk_fallback mtight">作</span><span class="mclose mtight">)</span><span class="mrel mtight">∼</span><span class="mord cjk_fallback mtight">策</span><span class="mord cjk_fallback mtight">略</span><span class="mord cjk_fallback mtight">的</span><span class="mord cjk_fallback mtight">占</span><span class="mord cjk_fallback mtight">用</span><span class="mord cjk_fallback mtight">度</span><span class="mord cjk_fallback mtight">量</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord cjk_fallback">奖</span><span class="mord cjk_fallback">励</span><span class="mord cjk_fallback">函</span><span class="mord cjk_fallback">数</span><span class="mopen">(</span><span class="mord cjk_fallback">状</span><span class="mord cjk_fallback">态</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord cjk_fallback">动</span><span class="mord cjk_fallback">作</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></span></p>
<p>二者优化的途径是不同的，监督学习直接<strong>通过优化模型对于数据特征的输出来优化目标</strong>，即修改目标函数而数据分布不变；强化学习则<strong>通过改变策略来调整智能体和环境交互数据的分布</strong>，进而优化目标，<strong>修改数据分布而目标函数不变。</strong></p>
<p>但现在 RLFT 真的只能微调（顶多几个 epoch 就结束了），不管有没有收敛都得结束，再调下去原来的能力也要丢失了。目前仍缺少一个长期的、稳定的 RLFT 方法。</p>
<h3 id="4-数据"><a class="markdownIt-Anchor" href="#4-数据"></a> 4. 数据</h3>
<p>在强化学习中，<strong>数据是在智能体与环境交互的过程中得到的</strong>。如果智能体不采取某个决策动作，那么该动作对应的数据就永远无法被观测到，所以当前智能体的训练数据来自之前智能体的决策结果。<strong>智能体的策略不同，与环境交互所产生的数据分布就不同。</strong></p>
<p>具体而言，<strong>强化学习中有一个关于数据分布的概念，叫作占用度量（occupancy measure）</strong>，其具体的数学定义和性质会在第3章讨论，在这里我们只做简要的陈述：<strong>归一化的占用度量用于衡量在一个智能体决策与一个动态环境的交互过程中，采样到一个具体的状态动作对（state-action pair）的概率分布</strong>。</p>
<p>占用度量有一个很重要的性质：**给定两个策略及其与一个动态环境交互得到的两个占用度量，那么当且仅当这两个占用度量相同时，这两个策略相同。**也就是说，如果一个智能体的策略有所改变，那么它和环境交互得到的占用度量也会相应改变。</p>
<p>根据占用度量这一重要的性质，我们可以领悟到强化学习本质的思维方式。</p>
<ul>
<li>**强化学习的策略在训练中会不断更新，其对应的数据分布（即占用度量）也会相应地改变。**因此，强化学习的一大难点就在于，智能体看到的数据分布是随着智能体的学习而不断发生改变的。</li>
<li>由于奖励建立在状态动作对之上，策略对应的价值其实就是占用度量下对应的奖励的期望，因此<strong>寻找最优策略</strong>对应着<strong>寻找最优占用度量</strong>。</li>
</ul>
<br>
<h2 id="第二节-多臂老虎机"><a class="markdownIt-Anchor" href="#第二节-多臂老虎机"></a> 第二节 多臂老虎机</h2>
<p><img src="https://hrl.boyuai.com/static/640.8908144b.png" alt="640.8908144b.png (640×321)" / srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%20300'%3E%3C/svg%3E" data-src="https://hrl.boyuai.com/static/640.8908144b.png" class="lozad post-image"></p>
<p>有一个拥有 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span></span></span></span> 根拉杆的老虎机，拉动每一根拉杆都对应一个关于奖励的概率分布 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span></span></span></span>。我们每次拉动其中一根拉杆，就可以从该拉杆对应的奖励概率分布中获得一个奖励 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span></span></span></span>。我们在各根拉杆的奖励概率分布未知的情况下从头开始尝试，目标是在操作 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span></span></span></span> 次拉杆后获得尽可能高的累积奖励。由于奖励的概率分布是未知的，因此我们需要在 “探索拉杆的获奖概率” 和 “根据经验选择获奖最多的拉杆” 中进行权衡。</p>
<p>有关多臂老虎机提出了算法的累积懊悔理论，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">ϵ</span></span></span></span>-贪心算法、上置信界算法和汤普森采样算法在多臂老虎机问题中十分常用，其中上置信界算法和汤普森采样方法均能保证对数的渐进最优累积懊悔。多臂老虎机问题与强化学习的一大区别在于其<strong>与环境的交互并不会改变环境</strong>，即多臂老虎机的每次交互的结果和以往的动作无关，所以可看作<strong>无状态的强化学习</strong>。第 3 章将开始在有状态的环境下讨论强化学习，即马尔可夫决策过程。</p>

  </div>
  <div>
    
      <div 
        class="post-note note-warning copyright" 
        style="margin-top: 42px">
        <p>
          <span style="font-weight: bold;">作者：</span><a 
            target="_blank" 
            rel="nofollow noopener noreferrer" 
            href="/about">
            天泽龟
          </a>
        </p>
        <p>
          <span style="font-weight: bold;">文章链接：</span><a 
            target="_blank" 
            rel="nofollow noopener noreferrer" 
            href="https://tzturtle.moe/2024/10/22/rl-1/">
            https://tzturtle.moe/2024/10/22/rl-1/
          </a>
        </p>
        <p><span style="font-weight: bold;">版权声明：</span>本博客所有文章除特别声明外，均采用<a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0 协议</a>。转载请注明出处！</p>
      </div>
    
  </div>
</article>
<div class="nav">
  
    <div class="nav-item-prev">
      <a 
        href="/2024/10/28/parallel-training-survey/" 
        class="nav-link">
        <i class="iconfont icon-left nav-prev-icon"></i>
        <div>
          <div class="nav-label">上一篇</div>
          
            <div class="nav-title">【转载】浅谈大模型分布式训练并行技术 </div>
          
        </div>
      </a>
    </div>
  
  
    <div class="nav-item-next">
      <a 
        href="/2024/10/15/openai-o1-survey/" 
        class="nav-link">
        <div>
          <div class="nav-label">下一篇</div>
          
            <div class="nav-title">OpenAI o1 调查报告 </div>
          
        </div>
        <i class="iconfont icon-right nav-next-icon"></i>
      </a>
    </div>
  
</div>

  <div 
    class="card card-content comment-card" 
    style="margin-top: 16px;">
    <div class="comment-card-title">评论</div>
    
  <div id="vcomments"></div>
  
  <script>
    loadScript("//unpkg.com/valine/dist/Valine.min.js");
    var oldLoadVa = window.onload;
    window.onload = function () {
      oldLoadVa && oldLoadVa();
      new Valine({
        el: '#vcomments',
        appId: '4CiiPBXpbjDnPvIIwfuEPEY6-gzGzoHsz',
        appKey: '3AQY35K3Laq9fLvTG2uOHDUT',
        placeholder: '留下你的评论...',
        path: window.location.pathname,
        avatar: 'identicon',
        meta: ["nick","mail","link"],
        pageSize: '10',
        lang: '',
        visitor: 'false',
        highlight: true,
        recordIP: false,
        
        
        
        enableQQ: 'true',
        requiredFields: [],
      });
    };
  </script>

  </div>

<div 
  class="card card-content toc-card" 
  id="mobiletoc">
  <div class="toc-header">
  <i 
    class="iconfont icon-menu" 
    style="padding-right: 2px;">
  </i>目录
</div>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E8%8A%82-%E5%88%9D%E6%8E%A2%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0"><span class="toc-text"> 第一节 初探强化学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%A6%82%E5%BF%B5"><span class="toc-text"> 1. 概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%8E%AF%E5%A2%83"><span class="toc-text"> 2. 环境</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E7%9B%AE%E6%A0%87"><span class="toc-text"> 3. 目标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%95%B0%E6%8D%AE"><span class="toc-text"> 4. 数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E8%8A%82-%E5%A4%9A%E8%87%82%E8%80%81%E8%99%8E%E6%9C%BA"><span class="toc-text"> 第二节 多臂老虎机</span></a></li></ol>
</div></main>
            <aside class="left-column">
              
              <div class="card card-author">
                
  <img 
    src="https://i.loli.net/2021/07/16/yKghkEQWcY34rOU.jpg" 
    class="author-img" 
    alt="author avatar">

<p class="author-name">天泽龟</p>
<p class="author-description">天泽龟的龟是龟裂的龟哦。</p>
<div class="author-message">
  <a 
    class="author-posts-count" 
    href="/archives">
    <span>50</span>
    <span>文章</span>
  </a>
  <a 
    class="author-categories-count" 
    href="/categories">
    <span>5</span>
    <span>分类</span>
  </a>
  <a 
    class="author-tags-count" 
    href="/tags">
    <span>13</span>
    <span>标签</span>
  </a>
</div>

  <div class="author-card-society">
    
      <div class="author-card-society-icon">
        <a target="_blank" rel="noopener" href="https://space.bilibili.com/12645985">
          <i class="iconfont icon-bilibili society-icon"></i>
        </a>
      </div>
    
      <div class="author-card-society-icon">
        <a target="_blank" rel="noopener" href="https://github.com/TURLEing">
          <i class="iconfont icon-github society-icon"></i>
        </a>
      </div>
    
      <div class="author-card-society-icon">
        <a target="_blank" rel="noopener" href="https://turleing.github.io/about/">
          <i class="iconfont icon-mail society-icon"></i>
        </a>
      </div>
    
  </div>

              </div>
               <div class="sticky-tablet">
  
  
    <article class="display-when-two-columns spacer">
      <div class="card card-content toc-card">
        <div class="toc-header">
  <i 
    class="iconfont icon-menu" 
    style="padding-right: 2px;">
  </i>目录
</div>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E8%8A%82-%E5%88%9D%E6%8E%A2%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0"><span class="toc-text"> 第一节 初探强化学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%A6%82%E5%BF%B5"><span class="toc-text"> 1. 概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%8E%AF%E5%A2%83"><span class="toc-text"> 2. 环境</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E7%9B%AE%E6%A0%87"><span class="toc-text"> 3. 目标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%95%B0%E6%8D%AE"><span class="toc-text"> 4. 数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E8%8A%82-%E5%A4%9A%E8%87%82%E8%80%81%E8%99%8E%E6%9C%BA"><span class="toc-text"> 第二节 多臂老虎机</span></a></li></ol>
      </div>
    </article>
  
  
  <article class="card card-content categories-widget">
    <div class="categories-card">
  <div class="categories-header">
    <i 
      class="iconfont icon-fenlei" 
      style="padding-right: 2px;">
    </i>分类
  </div>
  <div class="categories-list">
    
      <a href="/categories/%E7%94%9F%E6%B4%BB%E5%88%86%E4%BA%AB/">
        <div class="categories-list-item">
          生活分享
          <span class="categories-list-item-badge">6</span>
        </div>
      </a>
    
      <a href="/categories/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B/">
        <div class="categories-list-item">
          算法竞赛
          <span class="categories-list-item-badge">12</span>
        </div>
      </a>
    
      <a href="/categories/%E4%B8%93%E4%B8%9A%E5%AD%A6%E4%B9%A0/">
        <div class="categories-list-item">
          专业学习
          <span class="categories-list-item-badge">22</span>
        </div>
      </a>
    
      <a href="/categories/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/">
        <div class="categories-list-item">
          科研学习
          <span class="categories-list-item-badge">6</span>
        </div>
      </a>
    
      <a href="/categories/%E7%A4%BE%E5%9B%A2%E6%8E%A8%E9%80%81/">
        <div class="categories-list-item">
          社团推送
          <span class="categories-list-item-badge">2</span>
        </div>
      </a>
    
  </div>
</div>
  </article>
  
  <article class="card card-content tags-widget">
    <div class="tags-card">
  <div class="tags-header">
    <i 
      class="iconfont icon-biaoqian" 
      style="padding-right: 2px;">
    </i>热门标签
  </div>
  <div class="tags-list">
    
      <a 
        href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/" 
        title="计算机组成原理">
        <div class="tags-list-item">计算机组成原理</div>
      </a>
    
      <a 
        href="/tags/%E9%9A%8F%E7%AC%94/" 
        title="随笔">
        <div class="tags-list-item">随笔</div>
      </a>
    
      <a 
        href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" 
        title="强化学习">
        <div class="tags-list-item">强化学习</div>
      </a>
    
      <a 
        href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" 
        title="操作系统">
        <div class="tags-list-item">操作系统</div>
      </a>
    
      <a 
        href="/tags/NLP/" 
        title="NLP">
        <div class="tags-list-item">NLP</div>
      </a>
    
      <a 
        href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/" 
        title="字符串">
        <div class="tags-list-item">字符串</div>
      </a>
    
      <a 
        href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" 
        title="分布式">
        <div class="tags-list-item">分布式</div>
      </a>
    
      <a 
        href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/" 
        title="大模型">
        <div class="tags-list-item">大模型</div>
      </a>
    
      <a 
        href="/tags/%E5%A4%9A%E9%A1%B9%E5%BC%8F/" 
        title="多项式">
        <div class="tags-list-item">多项式</div>
      </a>
    
      <a 
        href="/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" 
        title="推荐系统">
        <div class="tags-list-item">推荐系统</div>
      </a>
    
      <a 
        href="/tags/%E5%BC%BA%E8%BF%9E%E9%80%9A%E5%88%86%E9%87%8F/" 
        title="强连通分量">
        <div class="tags-list-item">强连通分量</div>
      </a>
    
      <a 
        href="/tags/%E7%BA%BF%E6%80%A7%E5%9F%BA/" 
        title="线性基">
        <div class="tags-list-item">线性基</div>
      </a>
    
      <a 
        href="/tags/%E5%8D%9A%E5%BC%88%E8%AE%BA/" 
        title="博弈论">
        <div class="tags-list-item">博弈论</div>
      </a>
    
  </div>
</div>
  </article>
  
  
</div>
            </aside>
            <aside class="right-column">
              <div class="sticky-widescreen">
  
  
    <article class="card card-content toc-card">
      <div class="toc-header">
  <i 
    class="iconfont icon-menu" 
    style="padding-right: 2px;">
  </i>目录
</div>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E8%8A%82-%E5%88%9D%E6%8E%A2%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0"><span class="toc-text"> 第一节 初探强化学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%A6%82%E5%BF%B5"><span class="toc-text"> 1. 概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%8E%AF%E5%A2%83"><span class="toc-text"> 2. 环境</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E7%9B%AE%E6%A0%87"><span class="toc-text"> 3. 目标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%95%B0%E6%8D%AE"><span class="toc-text"> 4. 数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E8%8A%82-%E5%A4%9A%E8%87%82%E8%80%81%E8%99%8E%E6%9C%BA"><span class="toc-text"> 第二节 多臂老虎机</span></a></li></ol>
    </article>
  
  
  <article class="card card-content">
    <div class="recent-posts-card">
  <div class="recent-posts-header">
    <i 
      class="iconfont icon-wenzhang_huaban" 
      style="padding-right: 2px;">
    </i>最近文章
  </div>
  <div class="recent-posts-list">
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2024-11-10</div>
        <a href="/2024/11/10/rl-3/"><div class="recent-posts-item-content">《动手学强化学习》学习笔记【三】</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2024-11-09</div>
        <a href="/2024/11/09/rl-2/"><div class="recent-posts-item-content">《动手学强化学习》学习笔记【二】</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2024-10-28</div>
        <a href="/2024/10/28/parallel-training-survey/"><div class="recent-posts-item-content">【转载】浅谈大模型分布式训练并行技术</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2024-10-22</div>
        <a href="/2024/10/22/rl-1/"><div class="recent-posts-item-content">《动手学强化学习》学习笔记【一】</div></a>
      </div>
    
  </div>
</div>
  </article>
  
  
</div>
            </aside>
          </div>
        </div>
      </div>
    </div>
     
    <footer class="footer">
  <div class="footer-container">
    <div>
      <div class="footer-dsc">
        <span>
          Copyright ©
          
            2020 -
          
          2024
        </span>
        &nbsp;
        <a 
          href="/" 
          class="footer-link">
          天泽龟的龟壳屋
        </a>
      </div>
    </div>

    
      <div class="footer-dsc">
        
          Powered by
          <a 
            href="https://hexo.io/" 
            class="footer-link" 
            target="_blank" 
            rel="nofollow noopener noreferrer">
            &nbsp;Hexo
          </a>
        
        
          <span>&nbsp;|&nbsp;</span>
        
        
          Theme -
          <a 
            href="https://github.com/theme-kaze" 
            class="footer-link" 
            target="_blank"
            rel="nofollow noopener noreferrer">
            &nbsp;Kaze
          </a>
        
      </div>
    
    
    
    
      <div class="footer-dsc">
        
          本站总访问量<span id="busuanzi_value_site_pv"></span>次
        
        
          <span>&nbsp;|&nbsp;</span>
        
        
          本站总访客数<span id="busuanzi_value_site_uv"></span>次
        
      </div>
      
    
</footer> 
    
  <a 
    role="button" 
    id="scrollbutton" 
    class="basebutton" 
    aria-label="回到顶部">
    <i class="iconfont icon-arrowleft button-icon"></i>
  </a>

<a 
  role="button" 
  id="menubutton" 
  class="basebutton">
  <i class="iconfont icon-menu button-icon"></i>
</a>
<a 
  role="button" 
  id="popbutton" 
  class="basebutton" 
  aria-label="控制中心">
  <i class="iconfont icon-expand button-icon"></i>
</a>
<a 
  role="button" 
  id="darkbutton" 
  class="basebutton darkwidget" 
  aria-label="夜色模式">
  <i class="iconfont icon-weather button-icon"></i>
</a>
<a 
  role="button" 
  id="searchbutton" 
  class="basebutton searchwidget" 
  aria-label="搜索">
  <i class="iconfont icon-search button-icon"></i>
</a> 
     
     
      

  
  
    
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css">

  
 
     
     
      <script>
  var addImgLayout = function () {
    var img = document.querySelectorAll('.post-content img')
    var i
    for (i = 0; i < img.length; i++) {
      var wrapper = document.createElement('a')
      wrapper.setAttribute('href', img[i].getAttribute('data-src'))
      wrapper.setAttribute('aria-label', 'illustration')
      wrapper.style.cssText =
        'width: 100%; display: flex; justify-content: center;'
      if (img[i].alt) wrapper.dataset.caption = img[i].alt
      wrapper.dataset.nolink = true
      img[i].before(wrapper)
      wrapper.append(img[i])
      var divWrap = document.createElement('div')
      divWrap.classList.add('gallery')
      wrapper.before(divWrap)
      divWrap.append(wrapper)
    }
    baguetteBox.run('.gallery')
  }
</script>
<script>
  loadScript(
    "/js/lib/lightbox/baguetteBox.min.js",
    addImgLayout
  )
</script>
 
     
     
    <script src="/js/main.js"></script> 
    
      <script> 
        loadScript('/js/lib/busuanzi.min.js') 
      </script>
     
    
      <script>
        var addLazyload = function () {
          var observer = lozad('.lozad', {
            load: function (el) {
              el.srcset = el.getAttribute('data-src')
            },
            loaded: function (el) {
              el.classList.add('loaded')
            },
          })
          observer.observe()
        }
      </script>
      <script>
        loadScript('/js/lib/lozad.min.js', addLazyload)
      </script>
     
    
    
  </body>
</html>
